{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "convolutional-neural-networks",
      "graded_item_id": "OMdut",
      "launcher_item_id": "bbBOL"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "YOLO test notebook",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrAlexSanz/YOLO-test/blob/master/YOLO_test_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyksyLElG6jA",
        "colab_type": "text"
      },
      "source": [
        "This notebook implements a simple object detection model. This is greatly inspired on the link here: [Awesome blog post!](https://hackernoon.com/object-detection-in-google-colab-with-custom-dataset-5a7bb2b0e97e)\n",
        "\n",
        "So far this is the best tutorial I have found. Many people implement this for a given system (linux, ios...) or with a video feed. This is ok, but I want to focus on what I want to do, object detection. Next step is a mask/semantic segmentation and on a much longer time scale, caption generation.\n",
        "\n",
        "nother useful link, stanford course presentation about this topic: [Slides](http://cs231n.stanford.edu/slides/2018/cs231n_2018_ds06.pdf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvE8OnXqYwQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4f9a356-39e9-4ab9-9e55-e7b50da11fd7"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = [18, 12]\n",
        "import h5py\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from keras import layers, optimizers\n",
        "from keras.layers import Input, Dense, Conv2D, Activation, ZeroPadding2D, BatchNormalization, Flatten, Add\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "from keras.utils import layer_utils, plot_model, to_categorical\n",
        "\n",
        "from keras.callbacks import History, ModelCheckpoint\n",
        "\n",
        "keras.backend.set_image_data_format('channels_last')\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"Everything imported correctly\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Everything imported correctly\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExHcB3PtYq-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6b00b158-76ae-4623-f6b0-090e7dc6bc2d"
      },
      "source": [
        "#First remove the folder and everything it contains.\n",
        "\n",
        "!rm -rf YOLO-test\n",
        "\n",
        "#Now I clone the repository and everything works.\n",
        "\n",
        "! git clone https://github.com/DrAlexSanz/YOLO-test.git"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'YOLO-test'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 222 (delta 2), reused 58 (delta 0), pack-reused 141\n",
            "Receiving objects: 100% (222/222), 85.41 MiB | 28.88 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zewK3NVZNHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Maybe I use this later. Just in case I leave it here to avoid copying it later\n",
        "\n",
        "#Now read data\n",
        "\n",
        "# with h5py.File(\"Resnet/test_signs.h5\") as test:\n",
        "#   test_x_1 = np.array(test[\"test_set_x\"][:]) # your train set features\n",
        "#   test_y_1 = np.array(test[\"test_set_y\"][:]) # your train set labels\n",
        "#   classes = np.array(test[\"list_classes\"][:]) # the list of classes\n",
        "\n",
        "# with h5py.File(\"Resnet/train_signs.h5\") as train:\n",
        "#   train_x_1 = np.array(train[\"train_set_x\"][:]) # train set features\n",
        "#   train_y_1 = np.array(train[\"train_set_y\"][:]) # train set labels\n",
        "\n",
        "# print(\"Everything loaded and imported\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}